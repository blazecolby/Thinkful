{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import swifter\n",
    "mpl.style.use('classic')\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place data in dataframe\n",
    "df = pd.read_csv(\n",
    "    'LoanStats3d.csv',\n",
    "    skipinitialspace=True,\n",
    "    header=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = df.drop('loan_status', 1)\n",
    "Y = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = pd.to_numeric(df['id'], errors='coerce')\n",
    "df['int_rate'] = pd.to_numeric(df['int_rate'].str.strip('%'), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical options over 30 count\n",
    "df.drop(['url', 'emp_title', 'zip_code', 'earliest_cr_line', 'revol_util', 'sub_grade', 'addr_state', 'desc'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create\n",
    "X = df.drop('loan_status', 1)\n",
    "Y = df['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(rfc.fit(X, Y).feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(list(X.columns), importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score:\n",
      " [0.97910285 0.98043267 0.98119256 0.98178623 0.97573023 0.97848492\n",
      " 0.9532879  0.98052673 0.98019332 0.98024035]\n",
      "Cross-Validation Mean:\n",
      " 0.9770977744992895\n",
      "Cross-Validation +/- (2x STD):\n",
      " 0.016196435144993436\n"
     ]
    }
   ],
   "source": [
    "cvscore = cross_val_score(rfc, X, Y, cv=10, n_jobs=-1)\n",
    "print('Cross-Validation Score:\\n', cvscore)\n",
    "print('Cross-Validation Mean:\\n', cvscore.mean())\n",
    "print('Cross-Validation +/- (2x STD):\\n', (cvscore.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last_pymnt_amnt',\n",
       " 'last_pymnt_d_Jan-2017',\n",
       " 'out_prncp_inv',\n",
       " 'next_pymnt_d_Feb-2017',\n",
       " 'out_prncp',\n",
       " 'total_rec_prncp',\n",
       " 'total_pymnt_inv',\n",
       " 'last_credit_pull_d_Jan-2017',\n",
       " 'total_pymnt',\n",
       " 'last_pymnt_d_Dec-2016',\n",
       " 'recoveries',\n",
       " 'last_pymnt_d_Nov-2016',\n",
       " 'collection_recovery_fee',\n",
       " 'total_rec_int',\n",
       " 'last_pymnt_d_Oct-2016',\n",
       " 'funded_amnt',\n",
       " 'next_pymnt_d_Jan-2017',\n",
       " 'installment']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ranked = []\n",
    "for i in range(0, len(feature_importances)):\n",
    "    if feature_importances[i][1] >= 0.01:\n",
    "        features_ranked.append(feature_importances[i][0])\n",
    "        \n",
    "features_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = pd.DataFrame(X.loc[:, features_ranked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['last_pymnt_d_Jan-2017', 'out_prncp', 'out_prncp_inv', 'next_pymnt_d_Feb-2017']\n",
    "\n",
    "means = set1[group1].mean(axis=0)\n",
    "stds = set1[group1].std(axis=0)\n",
    "set1['var1'] = ((set1[group1] - means) / stds).mean(axis=1)\n",
    "set1['var1'] = set1['var1'] - set1['var1'].min()\n",
    "set1['var1'] = set1['var1']/set1['var1'].max()\n",
    "\n",
    "set1.drop(group1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group2 = ['last_pymnt_amnt', 'total_rec_prncp', 'total_pymnt_inv', 'total_pymnt']\n",
    "\n",
    "means = set1[group2].mean(axis=0)\n",
    "stds = set1[group2].std(axis=0)\n",
    "set1['var2'] = ((set1[group2] - means) / stds).mean(axis=1)\n",
    "set1['var2'] = set1['var2'] - set1['var2'].min()\n",
    "set1['var2'] = set1['var2']/set1['var2'].max()\n",
    "\n",
    "set1.drop(group2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "group3 = ['recoveries', 'collection_recovery_fee']\n",
    "\n",
    "means = set1[group3].mean(axis=0)\n",
    "stds = set1[group3].std(axis=0)\n",
    "set1['var3'] = ((set1[group3] - means) / stds).mean(axis=1)\n",
    "set1['var3'] = set1['var3'] - set1['var3'].min()\n",
    "set1['var3'] = set1['var3']/set1['var3'].max()\n",
    "\n",
    "\n",
    "set1.drop(group3, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score:\n",
      " [0.96276507 0.97098145 0.97392605 0.97729809 0.96874852 0.97337924\n",
      " 0.97195374 0.97568216 0.97090745 0.97767539]\n",
      "Cross-Validation Mean:\n",
      " 0.9723317171435228\n",
      "Cross-Validation +/- (2x STD):\n",
      " 0.00840092934917324\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = df['loan_status']\n",
    "\n",
    "cvscore = cross_val_score(rfc, set1, Y, cv=10, n_jobs=-1)\n",
    "print('Score:\\n', cvscore)\n",
    "print('Mean:\\n', cvscore.mean())\n",
    "print('STD', (cvscore.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score:\n",
      " [0.96276507 0.97098145 0.97392605 0.97729809 0.96874852 0.97337924\n",
      " 0.97195374 0.97568216 0.97090745 0.97767539]\n",
      "Cross-Validation Mean:\n",
      " 0.9723317171435228\n",
      "Cross-Validation +/- (2x STD):\n",
      " 0.00840092934917324\n"
     ]
    }
   ],
   "source": [
    "cvscore = cross_val_score(rfc, set1, Y, cv=10, n_jobs=-1)\n",
    "print('Score', cvscore)\n",
    "print('Mean', cvscore.mean())\n",
    "print('STD', (cvscore.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score:\n",
      " [0.86542709 0.90361188 0.89401819 0.90919237 0.87055331 0.9115412\n",
      " 0.89774158 0.89479684 0.90101408 0.91462024]\n",
      "Cross-Validation Mean:\n",
      " 0.8962516784899247\n",
      "Cross-Validation +/- (2x STD):\n",
      " 0.03121137452962254\n"
     ]
    }
   ],
   "source": [
    "cvscore = cross_val_score(rfc, set1.loc[:,['var1','var2','var3']], Y, cv=10, n_jobs=-1)\n",
    "print('Score:\\n', cvscore)\n",
    "print('Mean:\\n', cvscore.mean())\n",
    "print('STD', (cvscore.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscore = cross_val_score(rfc, set1, Y, cv=10, n_jobs=-1)\n",
    "print('Score:\\n', cvscore)\n",
    "print('Mean:\\n', cvscore.mean())\n",
    "print('STD', (cvscore.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conduct PCA\n",
    "# pca = PCA(n_components=4)\n",
    "\n",
    "# # data vs model parallelism -- multi core parameter\n",
    "\n",
    "# # Fit data to PCA function, then transform\n",
    "# pca.fit(x)\n",
    "# principalComponents = pca.transform(x)\n",
    "# # Place in dataframe\n",
    "# principalDf = pd.DataFrame(data = principalComponents)\n",
    "# # Concatenate dependents/independents to single dataframe\n",
    "# finalDf = pd.concat([principalDf, dd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA().fit(x)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as you can see by using feature importance it is possible to weed out the most important features. I started out using PCA but couldn't find a way to rank the data on a per feature basis. The feature importance allowed me to see that payment related variable were among the top of the importance list, as well as outstanding principal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
