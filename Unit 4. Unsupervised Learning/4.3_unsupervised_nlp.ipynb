{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import gutenberg\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantics = the meaning of a word\n",
    "# Latent Semantic Analysis = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term-document matrix; columns=sentences; rows=words; \n",
    "# ignore stopwords; lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term-document can be chunks, sentences, paragraphs, text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document frequency = sentences a word appears\n",
    "# Collection frequency = how often word appears\n",
    "# Inverse Document Frequency = log(Total Docs / Df)\n",
    "#           idf: tell to consider best as less important than others\n",
    "# tf-idf = weighted based on word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$idf_t=log \\dfrac N{df_t}$$\n",
    "\n",
    "$$tf-idf_{t,d}=(tf_{t,d})(idf_t)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 1.584962500721156 1.0 0 1.0 1.584962500721156 0 0 0 0\n",
      "5: 0 0 0 0 0 0.5849625007211562 1.0 1.584962500721156 1.0\n",
      "6: 0 0 0 0 0 0 1.0 0 2.0\n"
     ]
    }
   ],
   "source": [
    "print('4:', 1 * np.log2(6/2), 1 * np.log2(6/3), 0, 1 * np.log2(6/3), 1 * np.log2(6/2), 0, 0, 0, 0)\n",
    "print('5:', 0, 0, 0, 0, 0, 1 * np.log2(6/4), 1 * np.log2(6/3), 1* np.log2(6/2), 1*np.log2(6/3))\n",
    "print('6:', 0, 0, 0, 0, 0, 0, 1*np.log2(6/3), 0, 2*np.log2(6/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg.paras\n",
    "emma=gutenberg.paras('austen-persuasion.txt')\n",
    "emma_paras=[]\n",
    "for paragraph in emma: # clean austen text\n",
    "    para=paragraph[0]\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    emma_paras.append(' '.join(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1232\n",
      "Original sentence: \" My expressions startle you .\n",
      "Tf_idf vector: {'expressions': 1.0}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(emma_paras, test_size=0.4, random_state=0)\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english', lowercase=True, use_idf=True,norm=u'l2',smooth_idf=True )\n",
    "emma_tfidf=vectorizer.fit_transform(emma_paras)\n",
    "print('Number of features:', emma_s_tfidf.get_shape()[1])\n",
    "\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(emma_tfidf, test_size=0.4, random_state=0)\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% variance captured by components: 59.14611185886678\n"
     ]
    }
   ],
   "source": [
    "svd= TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"% variance captured by components:\",total_variance*100)\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "# for i in range(5):\n",
    "#     print('Component {}:'.format(i))\n",
    "#     print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Captain Harville smiled , as much as to say , \" Do you claim that for your sex ?\"\n",
      "Tf_idf: {'smiled': 0.5295823972120356, 'harville': 0.428412842064262, 'captain': 0.28306745311568243, 'say': 0.4010114352525943, 'claim': 0.5432012215568285}\n"
     ]
    }
   ],
   "source": [
    "print('Original:', X_train[4])\n",
    "print('Tf_idf:', tfidf_bypara[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd= TruncatedSVD(130)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
