{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPTO Analysis\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patents are dense\n",
    "- Patents are inherently dense. Typically, the information may be understood with enough time, or preexisting domain knowledge. \n",
    "\n",
    "### Patent breakdown\n",
    "- With each patent comes a set of pages; title page, description pages, graph pages, etc. Not all, but a lot of patents, come with a patent drawing/figure on the front page. Within that image, there are numbers to label each part of the figure; the aforementioned description pages explain what each image/figure is and what each given label on the image represents. \n",
    "\n",
    "### Project purpose\n",
    "- The purpose of this project is to use machine learning and other data science methods to identify each image label, match that label with its' corresponding description, and convert the description to laymens terms as well; as well as condense that information. \n",
    "\n",
    "### Extra steps\n",
    "- After this is done an additional step may be taken to take the condensed descriptions and place them next to each figure label. After the descriptions are placed, a search engine/recommendation engine may be created to allow for quicker access. \n",
    "\n",
    "### Benefit\n",
    "- An individual can save time by searching and finding relavant patents based on either laymens terms or domain jargon. They can then gain a quicker oversite by receiving only the images with their descriptions; with the option of looking at the full paper. \n",
    "\n",
    "### Where did this idea come from?\n",
    "- This project has grown out of a personal desire to understand patents, and feeling overwhelmed by the amount of data that there is. The hope is to make patents less of a black blox, and more of an opportunity for myself and for others. \n",
    "\n",
    "### Limitations\n",
    "- Due to limited time, this presentation/final product for this bootcamp will only be a part of the overall project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and organize your workspace\n",
    "_______________\n",
    "#### Below is a basic breakdown of what an image recognition project using tensorflow may look like. It's important to stay organized and keep things simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Tensorflow/scripts/\n",
    "└── preprocessing\n",
    "    ├── generate_tfrecord.py\n",
    "    └── xml_to_csv.py\n",
    "```\n",
    "```bash\n",
    "Tensorflow/workspace/\n",
    "└── patent_project\n",
    "    ├── annotations\n",
    "    │   ├── function_test.txt\n",
    "    │   ├── function_train.txt\n",
    "    │   ├── get_labels.ipynb\n",
    "    │   ├── labelmap.pbtxt\n",
    "    │   ├── test_labels.csv\n",
    "    │   ├── testing.txt\n",
    "    │   ├── train.record\n",
    "    │   ├── train_labels.csv\n",
    "    │   └── training.txt\n",
    "    ├── images\n",
    "    │   ├── tiff_to_jpg.ipynb\n",
    "    │   ├── test \n",
    "    │   │   ├── tif files\n",
    "    │   │   ├── xml files\n",
    "    │   └── train\n",
    "    │       ├── tif files\n",
    "    │       └── xml files\n",
    "    ├── pre-trained-model\n",
    "    │   └── ssd_inception_v2_coco\n",
    "    │       ├── checkpoint\n",
    "    │       ├── frozen_inference_graph.pb\n",
    "    │       ├── model.ckpt.data-00000-of-00001\n",
    "    │       ├── model.ckpt.index\n",
    "    │       ├── model.ckpt.meta\n",
    "    │       ├── pipeline.config\n",
    "    │       └── saved_model\n",
    "    │           ├── saved_model.pb\n",
    "    │           └── variables\n",
    "    ├── train.py\n",
    "    └── training\n",
    "        ├── checkpoint\n",
    "        ├── events.out.tfevents\n",
    "        ├── model.ckpt-0.data-00000-of-00001\n",
    "        ├── model.ckpt-0.index\n",
    "        ├── model.ckpt-0.meta\n",
    "        └── ssd_inception_v2_coco.config\n",
    "```\n",
    "- Set path when new terminal is opened. \n",
    "- !export PYTHONPATH=$PYTHONPATH:/Users/home/Documents/TensorFlow/models/research:/Users/home/Documents/TensorFlow/models/research/slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert images to correct format\n",
    "_______________\n",
    "#### The images that I downloaded in bulk from the uspto website came in a tiff format. Tensorflow doesn't support this so we need to convert it to a format such as jpg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "path = '/Users/home/Documents/Tensorflow/workspace/patent_project/images/'\n",
    "for root, dirs, files in os.walk(path, topdown=False):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n",
    "        if os.path.splitext(os.path.join(root, name))[1].lower() == \".tif\":\n",
    "            if os.path.isfile(os.path.splitext(os.path.join(root, name))[0] + \".jpg\"):\n",
    "                print(\"A jpg file already exists for %s\" % name)\n",
    "            # If a jpeg is *NOT* present, create one from the tiff.\n",
    "            else:\n",
    "                outfile = os.path.splitext(os.path.join(root, name))[0] + \".jpg\"\n",
    "                try:\n",
    "                    im = Image.open(os.path.join(root, name))\n",
    "                    print(\"Generating jpeg for %s\" % name)\n",
    "                    im.thumbnail(im.size)\n",
    "                    im.save(outfile, \"JPEG\", quality=100)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate images\n",
    "_______________\n",
    "#### Using labelImg you can annotate your images by placing bounding boxes around the items that you want to identify, this then creates an xml file for each image that has the bounding box boundries for each image and its' item. \n",
    "\n",
    "#### Once we have our xml files we can convert them into a single csv file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (\n",
    "                    root.find('filename').text, int(root.find('size')[0].text),\n",
    "                    int(root.find('size')[1].text), member[0].text,\n",
    "                    int(member[4][0].text), int(member[4][1].text),\n",
    "                    int(member[4][2].text), int(member[4][3].text)\n",
    "                    )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"XML-to-CSV\")\n",
    "    parser.add_argument(\"-i\", \"--inputDir\", help=\"Path to xml folder\", type=str)\n",
    "    parser.add_argument(\"-o\", \"--outputFile\", help=\"Output path to csv folder\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    if(args.inputDir is None):\n",
    "        args.inputDir = os.getcwd()\n",
    "    if(args.outputFile is None):\n",
    "        args.outputFile = args.inputDir + \"/labels.csv\"\n",
    "    assert(os.path.isdir(args.inputDir))\n",
    "    xml_df = xml_to_csv(args.inputDir)\n",
    "    xml_df.to_csv(args.outputFile, index=None)\n",
    "    print('Converted xml to csv.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get labels\n",
    "_______________\n",
    "#### Due to the number of total possible labels that we could have for our patent images it's best to create a script to turn our csv labels into our .pbtxt items.\n",
    "\n",
    "#### - First we create a txt file with all of the image labels: -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Grab Training labels\n",
    "filename = 'train_labels.csv'\n",
    "file = pd.read_csv(filename,header=None)\n",
    "file = file[3]\n",
    "end = '\\n'\n",
    "s = ' '\n",
    "ID = 1\n",
    "name = 'training.txt'\n",
    "for x in file[1:]:\n",
    "    out = ''\n",
    "    out += 'item' + s + '{' + end\n",
    "    out += s*2 + 'id:' + ' ' + (str(ID)) + end\n",
    "    out += s*2 + 'name:' + ' ' + '\\'' + str(x) + '\\'' + end\n",
    "    out += '}' + end    \n",
    "    ID += 1\n",
    "    with open(name, 'a') as f:\n",
    "        f.write(out)\n",
    "        \n",
    "# Grab Testing labels\n",
    "filename = 'test_labels.csv'\n",
    "file = pd.read_csv(filename,header=None)\n",
    "file = file[3]\n",
    "end = '\\n'\n",
    "s = ' '\n",
    "ID = ID\n",
    "name = 'testing.txt'\n",
    "for x in file[1:]:\n",
    "    out = ''\n",
    "    out += 'item' + s + '{' + end\n",
    "    out += s*2 + 'id:' + ' ' + (str(ID)) + end\n",
    "    out += s*2 + 'name:' + ' ' + '\\'' + str(x) + '\\'' + end\n",
    "    out += '}' + end    \n",
    "    ID += 1\n",
    "    with open(name, 'a') as f:\n",
    "        f.write(out)     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Then we our if else statement using the .txt to create a our tfrecords file: -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# generate_tfrecord if else statement\n",
    "# Testing\n",
    "filename = 'test_labels.csv'\n",
    "file = pd.read_csv(filename,header=None)\n",
    "file = file[3]\n",
    "end = '\\n'\n",
    "s = ' '\n",
    "ID = 0\n",
    "name = 'function_test.txt'\n",
    "for x in file[2:]:\n",
    "    out = ''\n",
    "    out += 'elif row_label == \\'' + str(x) + '\\':' + end\n",
    "    out += s*4 + 'return ' + str(ID) + end\n",
    "    ID += 1\n",
    "    with open(name, 'a') as f:\n",
    "        f.write(out)\n",
    "        \n",
    "# Training\n",
    "filename = 'train_labels.csv'\n",
    "file = pd.read_csv(filename,header=None)\n",
    "file = file[3]\n",
    "end = '\\n'\n",
    "s = ' '\n",
    "ID = ID\n",
    "name = 'function_train.txt'\n",
    "for x in file[2:]:\n",
    "    out = ''\n",
    "    out += 'elif row_label == \\'' + str(x) + '\\':' + end\n",
    "    out += s*4 + 'return ' + str(ID) + end\n",
    "    ID += 1\n",
    "    with open(name, 'a') as f:\n",
    "        f.write(out)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - From the above code we can copy and paste the results into the 'class_text_to_int()' function below -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../../models/research\")\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
    "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
    "flags.DEFINE_string('label', '', 'Name of class label')\n",
    "flags.DEFINE_string('img_path', '', 'Path to images')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'patent label 1':\n",
    "        return 1\n",
    "    elif row_label == 'patent label 2':\n",
    "        return 2\n",
    "    elif row_label == 'patent label 120':\n",
    "        return 120\n",
    "    elif row_label == 'patent label etc':\n",
    "        return etc\n",
    "    return None\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    # check if the image format is matching with your images.\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "def main(_):\n",
    "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
    "    path = os.path.join(os.getcwd(), FLAGS.img_path)\n",
    "    examples = pd.read_csv(FLAGS.csv_input)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
    "    print('Created TFRecords: {}'.format(output_path))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "_______________\n",
    "#### Tensorflow comes with a handful of models that are pretrained. We're actually able to take any of the pretrained models, take the calculated weights for any of the given models, and use those weights to train the set of annotated images that we created. \n",
    "\n",
    "#### I decided to go with the 'ssd_inception_v2_coco' model simply because it seemed like a good middle ground for speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once we have downloaded our pretrained model we can customize the config file to the number of files to files that we have creating up to this point:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 250 # this is the number of different labels that we came across when annotating our patent images.\n",
    "    image_resizer {\n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: \"ssd_inception_v2\"\n",
    "      depth_multiplier: 1.0\n",
    "      min_depth: 16\n",
    "      conv_hyperparams {\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            weight: 3.99999989895e-05\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            mean: 0.0\n",
    "            stddev: 0.0299999993294\n",
    "          }\n",
    "        }\n",
    "        activation: RELU_6\n",
    "        batch_norm {\n",
    "          decay: 0.999700009823\n",
    "          center: true\n",
    "          scale: true\n",
    "          epsilon: 0.0010000000475\n",
    "          train: true\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      convolutional_box_predictor {\n",
    "        conv_hyperparams {\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 3.99999989895e-05\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            truncated_normal_initializer {\n",
    "              mean: 0.0\n",
    "              stddev: 0.0299999993294\n",
    "            }\n",
    "          }\n",
    "          activation: RELU_6\n",
    "        }\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        use_dropout: false\n",
    "        dropout_keep_probability: 0.800000011921\n",
    "        kernel_size: 3\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      ssd_anchor_generator {\n",
    "        num_layers: 6\n",
    "        min_scale: 0.20000000298\n",
    "        max_scale: 0.949999988079\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.333299994469\n",
    "        reduce_boxes_in_lowest_layer: true\n",
    "      }\n",
    "    }\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 0.300000011921\n",
    "        iou_threshold: 0.600000023842\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    loss {\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      classification_loss {\n",
    "        weighted_sigmoid {\n",
    "        }\n",
    "      }\n",
    "      hard_example_miner {\n",
    "        num_hard_examples: 3000\n",
    "        iou_threshold: 0.990000009537\n",
    "        loss_type: CLASSIFICATION\n",
    "        max_negatives_per_positive: 3\n",
    "        min_negatives_per_image: 0\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "train_config {\n",
    "  batch_size: 24 # Good friends don't let you do batch sizes over 32. \n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "  optimizer {\n",
    "    rms_prop_optimizer {\n",
    "      learning_rate {\n",
    "        exponential_decay_learning_rate {\n",
    "          initial_learning_rate: 0.00400000018999\n",
    "          decay_steps: 800720\n",
    "          decay_factor: 0.949999988079\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.899999976158\n",
    "      decay: 0.899999976158\n",
    "      epsilon: 1.0\n",
    "    }\n",
    "  }\n",
    "  fine_tune_checkpoint: \"pre-trained-model/ssd_inception_v2_coco_2018_01_28/model.ckpt\"\n",
    "  from_detection_checkpoint: true\n",
    "  num_steps: 200000\n",
    "}\n",
    "train_input_reader {\n",
    "  label_map_path: 'annotations/labelmap.pbtxt'\n",
    "  tf_record_input_reader {\n",
    "    input_path: 'annotations/train.record'\n",
    "  }\n",
    "}\n",
    "eval_config {\n",
    "  num_examples: 8000\n",
    "  max_evals: 10\n",
    "  use_moving_averages: false\n",
    "}\n",
    "eval_input_reader {\n",
    "  label_map_path: 'annotations/labelmap.pbtxt'\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "  tf_record_input_reader {\n",
    "    input_path: 'annotations/test.record'\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "_______\n",
    "#### once we have all of the above code we can run a few commands to run all of the code and train our model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv.\n",
      "Successfully converted xml to csv.\n",
      "Successfully created the TFRecords: /Users/home/Documents/Tensorflow/workspace/training_demo/annotations/train.record\n",
      "Successfully created the TFRecords: /Users/home/Documents/Tensorflow/workspace/training_demo/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "# - Create xml to csv train data:\n",
    "!python /Users/home/Documents/Tensorflow/scripts/preprocessing/xml_to_csv.py \\\n",
    "-i /Users/home/Documents/Tensorflow/workspace/training_demo/images/train \\\n",
    "-o /Users/home/Documents/Tensorflow/workspace/training_demo/annotations/train_labels.csv\n",
    "\n",
    "# - Create xml to csv test data:\n",
    "!python /Users/home/Documents/Tensorflow/scripts/preprocessing/xml_to_csv.py \\\n",
    "-i /Users/home/Documents/Tensorflow/workspace/training_demo/images/test \\\n",
    "-o /Users/home/Documents/Tensorflow/workspace/training_demo/annotations/test_labels.csv\n",
    "\n",
    "# - Create record train data:\n",
    "!python \\\n",
    "/Users/home/Documents/Tensorflow/scripts/preprocessing/generate_tfrecord.py \\\n",
    "--label=patent \\\n",
    "--csv_input=/Users/home/Documents/Tensorflow/workspace/training_demo/annotations/train_labels.csv\\\n",
    "--img_path=/Users/home/Documents/Tensorflow/workspace/training_demo/images/train \\\n",
    "--output_path=/Users/home/Documents/Tensorflow/workspace/training_demo/annotations/train.record\n",
    "\n",
    "# - Create record test data:\n",
    "!python /Users/home/Documents/Tensorflow/scripts/preprocessing/generate_tfrecord.py \\\n",
    "--label=patent \\\n",
    "--csv_input=/Users/home/Documents/Tensorflow/workspace/training_demo/annotations/test_labels.csv \\\n",
    "--img_path=/Users/home/Documents/Tensorflow/workspace/training_demo/images/test \\\n",
    "--output_path=/Users/home/Documents/Tensorflow/workspace/training_demo/annotations/test.record\n",
    "\n",
    "# - Train model using model_main.py\n",
    "!python /Users/home/Documents/Tensorflow/workspace/training_demo/model_main.py \\\n",
    "--logtostderr \\\n",
    "--train_dir=/Users/home/Documents/Tensorflow/workspace/training_demo/training/ \\\n",
    "--pipeline_config_path=/Users/home/Documents/Tensorflow/workspace/training_demo/training/ssd_inception_v2_coco.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is an example output for our model. This shows varying sizes of our model, and what the Ave Precision & Ave Recall are. These two metrics look at the data that is relavant(our positives).\n",
    "\n",
    "- Ave Precision: True Positive / Actual Results <br />\n",
    "- Ave Recall: True Positive / Predicted Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.590\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.861\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.694\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.614\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once we run our model an event file will be created. This is where we can evaluate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.14.0 at http://blazes-mbp.ad.uvu.edu:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# - Tensorboard Allows us to see different aspects of our data.\n",
    "!tensorboard --logdir=/Users/home/Documents/Tensorflow/workspace/training_demo/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
